---
title: "Analyze a Whatsapp chat"
author: "Frederik Holmelund Kjaerskov"
date: "7 March 2018"
output:
  html_document:
    theme: null
  html_notebook:
    theme: paper
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analyze a Whatapp chat

Wanting to do some more word analysis I thought of areas of interest. Visting Google I quickly discovered that the Brönte sisters and Hemingway are popular subjects. I wanted something else and suddenly thought of my 3 year old Whatapp chat with my girlfriend. While the Whatapp chat can easily be exported as a text file from your phone (see e.g. [Whatsapp.com FAQ](https://faq.whatsapp.com/en/wp/22548236)) you still need to do some regualar expression housekeeping but the challenge was accepted. Therefore this post is about analyzing a Whatsapp chat. 

## Getting the Whatsapp chat right

Following the [instructions](https://faq.whatsapp.com/en/wp/22548236), the Whatsapp chat was emailed as a text file to my email adress. To see the contents I opened the file in my spreadsheet application of choice Google Sheets but Excel should work fine. It was fairly easy to import the text file and I ended up with a sheet with rows each containing time, date, sender and text messages. This I saved as a CSV file and read into R. 

```{r libraries, warning=FALSE, message=FALSE}
#Load libraries we will need 
# library("dplyr") # Data manipulation
# library("tidytext") # Text mining
# library("ggplot2") #Visualization
# library("tidyr") #Tidy data
# library("scales") #Used for scaling methods
# library("stringr") # string operations
# library("lubridate") #Date and time conversion
# library("purrr") # FP toolkit
# library("broom") # stat obj. into data frames
```


```{r readfile, warning=FALSE}
#Read file
cFile <- read.csv("Whatsappchat.csv",   header = FALSE, sep = ";",
                na.strings="", stringsAsFactors = FALSE, fill=TRUE, encoding = "UTF-8")
str(cFile)
```

See that we 
Next we construct a data frame containing the raw text data. 

```{r}
#Construct data frame
dfRawText <- data_frame(
             line = 1:nrow(cFile),
             Text = as.character(gsub("^.*\\w{1}[:][[:blank:]](.*$)","\\1",cFile$V1)),
             Year = as.character(gsub("^.*((\\d+){4}?).*","\\1",cFile$V1)),
             Month = as.character(gsub("^.*\\d+{2}[/](\\d+{2})[/]\\d+{4}.*","\\1",cFile$V1)),
             Date = as.character(gsub("^(\\d+{2}[/]\\d+{2}).*","\\1",cFile$V1)),
             Time = as.numeric(gsub("^.*((\\d+){2}[.]\\d+).*$","\\1",cFile$V1)),
             Sender = gsub("^.*[-][[:blank:]]((\\w+){2}).*$","\\1",cFile$V1),
             Timestamp = gsub("(^.*)[[:blank:]][-].*$","\\1",cFile$V1)
             )

#Correct timestamps
dfRawText$Timestamp <- gsub("\\/","-",dfRawText$Timestamp)
dfRawText$Timestamp <- gsub(",","",dfRawText$Timestamp)
dfRawText$Timestamp <- gsub("\\.",":",dfRawText$Timestamp)

#Alter text specific to the chat (not generic!)
dfRawText$Text <- gsub("henter", "hente", dfRawText$Text)
dfRawText$Text <- gsub("í{1}", "i", dfRawText$Text, ignore.case = TRUE)

#Identify problem rows and replace these rows with data from previous row
problemIdx <- !(dfRawText$Sender %in% c("Frederik", "Hlín"))

for (i in which(problemIdx==TRUE, arr.ind=TRUE)) {
  dfRawText$Year[i] <- dfRawText$Year[i-1]
  dfRawText$Month[i] <- dfRawText$Month[i-1]
  dfRawText$Time[i] <- dfRawText$Time[i-1]
  dfRawText$Sender[i] <- dfRawText$Sender[i-1]
  dfRawText$Date[i] <- dfRawText$Date[i-1]
  dfRawText$Timestamp[i] <- dfRawText$Timestamp[i-1]
  }

#Convert timestamps to date-time object
dfRawText$Timestamp <- dmy_hm(dfRawText$Timestamp)
```

```{r}
#Create data frame with words as tokens
dfTidyText <- dfRawText %>% unnest_tokens(word, Text)

#Read Danish stop words
tmp <- read.csv("DanishStopWords.txt",   header = FALSE, sep = "", encoding = "UTF-8")
StopWords <- data_frame(word = as.character(tmp[,1]))

#Remove stop words from text
dfTidyText <- dfTidyText %>% anti_join(StopWords)
```


```{r}
#Visualize word counts per year and sender
dfTidyText %>% 
  filter(str_detect(word, "[[:alpha:]]{3,}+")) %>%
  count(Year, Sender, word, sort=TRUE) %>%
  mutate(word = reorder(word, n)) %>%
  filter(n>70) %>%
  ggplot(aes(word,n, fill=Sender)) +
  facet_wrap(~Year, ncol=3, scales = "free_y") +
  geom_col() +
  xlab(NULL) +
  coord_flip() + 
  theme_minimal() 

#Calculate frequencies grouped by sender
frequency <- dfTidyText %>% 
  mutate(word = str_extract(word, "[[:alpha:]]{3,}+")) %>%
  group_by(Sender) %>% 
  count(word, sort = TRUE) %>% 
  left_join(dfTidyText %>% 
              group_by(Sender) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)

#Spread by Sender
frequency <- frequency %>% 
  select(Sender, word, freq) %>% 
  spread(Sender, freq) %>%
  arrange(Hlín, Frederik)

#Plot
ggplot(frequency, aes(Hlín, Frederik)) +
  geom_jitter(alpha = 0.05, size = 2, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = -1) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = "red") +
  theme_minimal() 

```


```{r}
#Calculate the logration of words used by sender
word_ratios <- dfTidyText %>%
  mutate(word = str_extract(word, "[[:alpha:]]{3,}+")) %>%
  count(word, Sender) %>%
  filter(sum(n) >= 10) %>%
  ungroup() %>%
  spread(Sender, n, fill = 0) %>%
  mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
  mutate(logratio = log(Hlín / Frederik)) %>%
  arrange(desc(logratio))

#Plot
word_ratios %>%
  group_by(logratio < 0) %>%
  top_n(20, abs(logratio)) %>%
  ungroup() %>%
  mutate(word = reorder(word, logratio)) %>%
  ggplot(aes(word, logratio, fill = logratio < 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ylab("log odds ratio (Frederik/Hlín)") +
  scale_fill_discrete(name = "", labels = c("Frederik", "Hlín"))

#filter(!str_detect(word, "^@")) %>%
```

```{r}
words_by_time <- dfTidyText %>%
  filter(str_detect(word, "[[:alpha:]]{3,}+")) %>%
  filter(Year %in% c(2016, 2017)) %>%
  mutate(time_floor = floor_date(Timestamp, unit = "1 month")) %>%
  count(time_floor, Sender, word) %>%
  ungroup() %>%
  group_by(Sender, time_floor) %>%
  mutate(time_total = sum(n)) %>%
  group_by(word) %>%
  mutate(word_total = sum(n)) %>%
  ungroup() %>%
  rename(count = n) %>%
  filter(word_total > 30)

nested_data <- words_by_time %>%
  nest(-word, -Sender) 

nested_models <- nested_data %>%
  mutate(models = map(data, ~ glm(cbind(count, time_total) ~ time_floor, ., family = "binomial")))

slopes <- nested_models %>%
  unnest(map(models, tidy)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))

top_slopes <- slopes %>% 
  filter(adjusted.p.value < 0.05)

top_slopes

words_by_time %>%
  inner_join(top_slopes, by = c("word", "Sender")) %>%
  filter(Sender == "Frederik") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency (Frederik)")

words_by_time %>%
  inner_join(top_slopes, by = c("word", "Sender")) %>%
  filter(Sender == "Hlín") %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1) +
  geom_line(size = 1.3) +
  labs(x = NULL, y = "Word frequency (Hlín)")

words_by_time %>%
  inner_join(top_slopes, by = c("word", "Sender")) %>%
  ggplot(aes(time_floor, count/time_total, color = word)) +
  facet_wrap(~ Sender, scales = "free_y", ncol=1) +
  geom_line(size = 1.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1) +
  labs(x = NULL, y = "Word frequency")
```


```{r}
#Find TF IDF, term frequencies as inverse document frequencies
#Count frequncies of word pr. "document"
dfTF_IDF <- dfTidyText %>% 
  filter(str_detect(word, "[[:alpha:]]{3,}+")) %>%
  count(Sender, word, sort=TRUE)
#Apply TF IDF transform
dfTF_IDF <- dfTF_IDF %>%
  bind_tf_idf(word, Sender, n) %>%
  arrange(desc(tf_idf))

#Plot inverse document frequencies
dfTF_IDF %>%
    arrange(desc(tf_idf)) %>%
    mutate(word = factor(word, levels = rev(unique(word)))) %>% 
    group_by(Sender) %>% 
    top_n(25) %>% 
    ungroup %>%
    ggplot(aes(word, tf_idf, fill = Sender)) +
    geom_col(show.legend = FALSE) +
    labs(x = NULL, y = "tf-idf") +
    facet_wrap(~Sender, ncol = 2, scales = "free") +
    coord_flip()
```
